{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup - mounting, dependencies, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_csv.py\n",
    "\n",
    "import csv\n",
    "path = 'interpolated.csv'\n",
    "train = 9000\n",
    "test = 3000\n",
    "def split(output, start=0, end=1):\n",
    "    with open(path, 'r', newline='') as f,open(output, 'w', newline='') as f_out:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        writer = csv.writer(f_out, delimiter=\",\")\n",
    "        for counter,row in enumerate(reader):\n",
    "                if counter >= end:\n",
    "                    break\n",
    "                if counter >= start:\n",
    "                    writer.writerow(row)  \n",
    "    with open(output, 'r') as f:\n",
    "        print(str(len(list(csv.reader(f,delimiter = \",\")))) + \" data points in \" + output) \n",
    "print(\"starting split_csv ...\")\n",
    "with open(path, 'r') as f:\n",
    "    reader = csv.reader(f,delimiter = \",\")\n",
    "    data = list(reader)\n",
    "    n = len(data)\n",
    "    print(str(n) + \" data points in interpolated.csv\")    \n",
    "split(\"interpolated_train.csv\", end=train)\n",
    "split(\"interpolated_test.csv\", start=train, end=(train+test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#komanda.py\n",
    "\n",
    "#1\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "#slim = tf.contrib.slim\n",
    "import tf_slim as slim\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "abs_path = \"/content/drive/MyDrive/PRBX_ROSBAG/colab_data/hmb1/\"  # colab/drive\n",
    "#ANCHOR - 2\n",
    "SEQ_LEN = 10\n",
    "BATCH_SIZE = 4 \n",
    "LEFT_CONTEXT = 5\n",
    "HEIGHT = 480\n",
    "WIDTH = 640\n",
    "CHANNELS = 3\n",
    "RNN_SIZE = 16 #32\n",
    "RNN_PROJ = 16 #32\n",
    "CSV_HEADER = \"index,timestamp,width,height,frame_id,filename,angle,torque,speed,lat,long,alt\".split(\",\")\n",
    "OUTPUTS = CSV_HEADER[-6:-3] # angle,torque,speed\n",
    "OUTPUT_DIM = len(OUTPUTS) # predict all features: steering angle, torque and vehicle speed\n",
    "#ANCHOR - 3\n",
    "class BatchGenerator(object):\n",
    "    def __init__(self, sequence, seq_len, batch_size):\n",
    "        self.sequence = sequence\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        seq_len = len(list(sequence))\n",
    "        chunk_size = 1 + (seq_len - 1) / batch_size\n",
    "        self.indices = [(i*chunk_size) % seq_len for i in range(batch_size)]\n",
    "    def next(self):\n",
    "        while True:\n",
    "            output = []\n",
    "            for i in range(self.batch_size):\n",
    "                idx = int(self.indices[i])\n",
    "                left_pad = self.sequence[idx - LEFT_CONTEXT:idx]\n",
    "                if len(left_pad) < LEFT_CONTEXT:\n",
    "                    left_pad = [self.sequence[0]] * (LEFT_CONTEXT - len(left_pad)) + left_pad\n",
    "                assert len(left_pad) == LEFT_CONTEXT\n",
    "                leftover = len(self.sequence) - idx\n",
    "                if leftover >= self.seq_len:\n",
    "                    result = self.sequence[idx:idx + self.seq_len]\n",
    "                else:\n",
    "                    result = self.sequence[idx:] + self.sequence[:self.seq_len - leftover]\n",
    "                assert len(result) == self.seq_len\n",
    "                self.indices[i] = (idx + self.seq_len) % len(self.sequence)\n",
    "                images, targets = list(zip(*result))\n",
    "                images_left_pad, _ = list(zip(*left_pad))\n",
    "                output.append((np.stack(images_left_pad + images), np.stack(targets)))\n",
    "            output = list(zip(*output))\n",
    "            output[0] = np.stack(output[0]) # batch_size x (LEFT_CONTEXT + seq_len)\n",
    "            output[1] = np.stack(output[1]) # batch_size x seq_len x OUTPUT_DIM\n",
    "            return output\n",
    "def read_csv(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [ln.strip().split(\",\")[-7:-3] for ln in f.readlines()]\n",
    "        lines = map(lambda x: (x[0], np.float32(x[1:])), lines) # imagefile, outputs\n",
    "        return lines\n",
    "def process_csv(filename, val=5):\n",
    "    sum_f = np.float128([0.0] * OUTPUT_DIM)\n",
    "    sum_sq_f = np.float128([0.0] * OUTPUT_DIM)\n",
    "    lines = read_csv(filename)\n",
    "    # leave val% for validation\n",
    "    train_seq = []\n",
    "    valid_seq = []\n",
    "    cnt = 0\n",
    "    for ln in lines:\n",
    "        if cnt < SEQ_LEN * BATCH_SIZE * (100 - val): \n",
    "            train_seq.append(ln)\n",
    "            sum_f += ln[1]\n",
    "            sum_sq_f += ln[1] * ln[1]\n",
    "        else:\n",
    "            valid_seq.append(ln)\n",
    "        cnt += 1\n",
    "        cnt %= SEQ_LEN * BATCH_SIZE * 100\n",
    "    mean = sum_f / len(train_seq)\n",
    "    var = sum_sq_f / len(train_seq) - mean * mean\n",
    "    std = np.sqrt(var)\n",
    "    print(len(train_seq), len(valid_seq))\n",
    "    print (mean, std) # we will need these statistics to normalize the outputs (and ground truth inputs)\n",
    "    return (train_seq, valid_seq), (mean, std)\n",
    "#ANCHOR - 4\n",
    "(train_seq, valid_seq), (mean, std) = process_csv(filename=\"interpolated_train.csv\", val=5) # concatenated interpolated.csv from rosbags \n",
    "test_seq = read_csv(\"interpolated_test.csv\") # interpolated.csv for testset filled with dummy values \n",
    "#ANCHOR - 5\n",
    "#layer_norm = lambda x: tf.compat.v1.estimator.layers.layer_norm(inputs=x, center=True, scale=True, activation_fn=None, trainable=True)\n",
    "layer_norm = tf.keras.layers.LayerNormalization(center=True, scale=True, trainable=True)\n",
    "def get_optimizer(loss, lrate):\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=lrate)\n",
    "    gradvars = optimizer.compute_gradients(loss)\n",
    "    gradients, v = list(zip(*gradvars))\n",
    "    [print(x.name) for x in v]\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 15.0)\n",
    "    return optimizer.apply_gradients(list(zip(gradients, v)))\n",
    "def apply_vision_simple(image, keep_prob, batch_size, seq_len, scope=None, reuse=None):\n",
    "    video = tf.reshape(image, shape=[batch_size, LEFT_CONTEXT + seq_len, HEIGHT, WIDTH, CHANNELS])\n",
    "    with tf.compat.v1.variable_scope(scope, 'Vision', [image], reuse=reuse):\n",
    "        net = slim.convolution(video, num_outputs=32, kernel_size=[3,12,12], stride=[1,6,6], padding=\"VALID\") #128\n",
    "        net = tf.compat.v1.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        aux1 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 32, activation_fn=None) #128\n",
    "        net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,2,2], padding=\"VALID\")\n",
    "        net = tf.compat.v1.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        aux2 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 32, activation_fn=None) #128    \n",
    "        net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "        net = tf.compat.v1.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        aux3 = slim.fully_connected(tf.reshape(net[:, -seq_len:, :, :, :], [batch_size, seq_len, -1]), 32, activation_fn=None) #128       \n",
    "        net = slim.convolution(net, num_outputs=64, kernel_size=[2,5,5], stride=[1,1,1], padding=\"VALID\")\n",
    "        net = tf.compat.v1.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        # at this point the tensor 'net' is of shape batch_size x seq_len x ...\n",
    "        aux4 = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 32, activation_fn=None) #128       \n",
    "        net = slim.fully_connected(tf.reshape(net, [batch_size, seq_len, -1]), 256, activation_fn=tf.nn.relu) #1024\n",
    "        net = tf.compat.v1.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        net = slim.fully_connected(net, 128, activation_fn=tf.nn.relu) #512\n",
    "        net = tf.compat.v1.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        net = slim.fully_connected(net, 64, activation_fn=tf.nn.relu) #256\n",
    "        net = tf.compat.v1.nn.dropout(x=net, keep_prob=keep_prob)\n",
    "        net = slim.fully_connected(net, 32, activation_fn=None) #128\n",
    "        return layer_norm(tf.compat.v1.nn.elu(net + aux1 + aux2 + aux3 + aux4)) # aux[1-4] are residual connections (shortcuts)\n",
    "class SamplingRNNCell(tf.compat.v1.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"Simple sampling RNN cell.\"\"\"\n",
    "  def __init__(self, num_outputs, use_ground_truth, internal_cell):\n",
    "    \"\"\"\n",
    "    if use_ground_truth then don't sample\n",
    "    \"\"\"\n",
    "    self._num_outputs = num_outputs\n",
    "    self._use_ground_truth = use_ground_truth # boolean\n",
    "    self._internal_cell = internal_cell # may be LSTM or GRU or anything  \n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._num_outputs, self._internal_cell.state_size # previous output and bottleneck state\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_outputs # steering angle, torque, vehicle speed\n",
    "  def __call__(self, inputs, state, scope=None):\n",
    "    (visual_feats, current_ground_truth) = inputs\n",
    "    prev_output, prev_state_internal = state\n",
    "    context = tf.concat([prev_output, visual_feats], axis=1)\n",
    "    new_output_internal, new_state_internal = self._internal_cell(context, prev_state_internal) # here the internal cell (e.g. LSTM) is called\n",
    "    #new_output = tf.compat.v1.estimator.layers.fully_connected(\n",
    "    new_output = slim.layers.fully_connected(\n",
    "        inputs=tf.concat([new_output_internal, prev_output, visual_feats], axis=1),\n",
    "        num_outputs=self._num_outputs,\n",
    "        activation_fn=None,\n",
    "        scope=\"OutputProjection\")\n",
    "    # if self._use_ground_truth == True, we pass the ground truth as the state; otherwise, we use the model's predictions\n",
    "    return new_output, (current_ground_truth if self._use_ground_truth else new_output, new_state_internal)\n",
    "#ANCHOR - 6\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # inputs  \n",
    "    learning_rate = tf.compat.v1.placeholder_with_default(input=1e-4, shape=())\n",
    "    keep_prob = tf.compat.v1.placeholder_with_default(input=1.0, shape=())\n",
    "    aux_cost_weight = 0.1 #tf.placeholder_with_default(input=0.1, shape=())    \n",
    "    inputs = tf.compat.v1.placeholder(shape=(BATCH_SIZE,LEFT_CONTEXT+SEQ_LEN), dtype=tf.string) # pathes to png files from the central camera\n",
    "    targets = tf.compat.v1.placeholder(shape=(BATCH_SIZE,SEQ_LEN,OUTPUT_DIM), dtype=tf.float32) # seq_len x batch_size x OUTPUT_DIM\n",
    "    targets_normalized = (targets - mean) / std\n",
    "    input_images = tf.stack([tf.io.decode_jpeg(tf.io.read_file((abs_path + x))) #tf.image.decode_png(tf.read_file(x))\n",
    "                            for x in tf.unstack(tf.reshape(inputs, shape=[(LEFT_CONTEXT+SEQ_LEN) * BATCH_SIZE]))])\n",
    "    input_images = -1.0 + 2.0 * tf.cast(input_images, tf.float32) / 255.0\n",
    "    input_images.set_shape([(LEFT_CONTEXT+SEQ_LEN) * BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\n",
    "    visual_conditions_reshaped = apply_vision_simple(image=input_images, keep_prob=keep_prob, \n",
    "                                                     batch_size=BATCH_SIZE, seq_len=SEQ_LEN)\n",
    "    visual_conditions = tf.compat.v1.reshape(visual_conditions_reshaped, [BATCH_SIZE, SEQ_LEN, -1])\n",
    "    visual_conditions = tf.compat.v1.nn.dropout(x=visual_conditions, keep_prob=keep_prob)    \n",
    "    rnn_inputs_with_ground_truth = (visual_conditions, targets_normalized)\n",
    "    rnn_inputs_autoregressive = (visual_conditions, tf.zeros(shape=(BATCH_SIZE, SEQ_LEN, OUTPUT_DIM), dtype=tf.float32))    \n",
    "    internal_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=RNN_SIZE, num_proj=RNN_PROJ)\n",
    "    cell_with_ground_truth = SamplingRNNCell(num_outputs=OUTPUT_DIM, use_ground_truth=True, internal_cell=internal_cell)\n",
    "    cell_autoregressive = SamplingRNNCell(num_outputs=OUTPUT_DIM, use_ground_truth=False, internal_cell=internal_cell)    \n",
    "    def get_initial_state(complex_state_tuple_sizes):\n",
    "        flat_sizes = tf.nest.flatten(complex_state_tuple_sizes)\n",
    "        init_state_flat = [tf.tile( \n",
    "            multiples=[BATCH_SIZE, 1], \n",
    "            input=tf.compat.v1.get_variable(\"controller_initial_state_%d\" % i, initializer=tf.zeros_initializer, shape=([1, s]), dtype=tf.float32))\n",
    "         for i,s in enumerate(flat_sizes)]\n",
    "        init_state = tf.nest.pack_sequence_as(complex_state_tuple_sizes, init_state_flat)\n",
    "        return init_state\n",
    "    def deep_copy_initial_state(complex_state_tuple):\n",
    "        flat_state = tf.nest.flatten(complex_state_tuple)\n",
    "        flat_copy = [tf.identity(s) for s in flat_state]\n",
    "        deep_copy = tf.nest.pack_sequence_as(complex_state_tuple, flat_copy)\n",
    "        return deep_copy    \n",
    "    controller_initial_state_variables = get_initial_state(cell_autoregressive.state_size)\n",
    "    controller_initial_state_autoregressive = deep_copy_initial_state(controller_initial_state_variables)\n",
    "    controller_initial_state_gt = deep_copy_initial_state(controller_initial_state_variables)\n",
    "    with tf.compat.v1.variable_scope(\"predictor\"):\n",
    "        out_gt, controller_final_state_gt = tf.compat.v1.nn.dynamic_rnn(cell=cell_with_ground_truth, inputs=rnn_inputs_with_ground_truth, \n",
    "                          sequence_length=[SEQ_LEN]*BATCH_SIZE, initial_state=controller_initial_state_gt, dtype=tf.float32,\n",
    "                          swap_memory=True, time_major=False)\n",
    "    with tf.compat.v1.variable_scope(\"predictor\", reuse=True):\n",
    "        out_autoregressive, controller_final_state_autoregressive = tf.compat.v1.nn.dynamic_rnn(cell=cell_autoregressive, inputs=rnn_inputs_autoregressive, \n",
    "                          sequence_length=[SEQ_LEN]*BATCH_SIZE, initial_state=controller_initial_state_autoregressive, dtype=tf.float32,\n",
    "                          swap_memory=True, time_major=False)    \n",
    "    mse_gt = tf.reduce_mean(tf.math.squared_difference(out_gt, targets_normalized))\n",
    "    mse_autoregressive = tf.reduce_mean(tf.math.squared_difference(out_autoregressive, targets_normalized))\n",
    "    mse_autoregressive_steering = tf.reduce_mean(tf.math.squared_difference(out_autoregressive[:, :, 0], targets_normalized[:, :, 0]))\n",
    "    steering_predictions = (out_autoregressive[:, :, 0] * std[0]) + mean[0]    \n",
    "    total_loss = mse_autoregressive_steering + aux_cost_weight * (mse_gt + mse_autoregressive)    \n",
    "    optimizer = get_optimizer(total_loss, learning_rate)\n",
    "    tf.compat.v1.summary.scalar(\"MAIN TRAIN METRIC: rmse_autoregressive_steering\", tf.math.sqrt(mse_autoregressive_steering))\n",
    "    tf.compat.v1.summary.scalar(\"rmse_gt\", tf.math.sqrt(mse_gt))\n",
    "    tf.compat.v1.summary.scalar(\"rmse_autoregressive\", tf.math.sqrt(mse_autoregressive))    \n",
    "    summaries = tf.compat.v1.summary.merge_all()\n",
    "    train_writer = tf.compat.v1.summary.FileWriter('v3/train_summary', graph=graph)\n",
    "    valid_writer = tf.compat.v1.summary.FileWriter('v3/valid_summary', graph=graph)\n",
    "    saver = tf.compat.v1.train.Saver(write_version=tf.compat.v1.train.SaverDef.V2)    \n",
    "#ANCHOR - 7\n",
    "#tf.config.gpu.set_per_process_memory_fraction(0.25)\n",
    "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "#gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "checkpoint_dir = os.getcwd() + \"/v3\"\n",
    "global_train_step = 0\n",
    "global_valid_step = 0\n",
    "KEEP_PROB_TRAIN = 0.25\n",
    "def do_epoch(session, sequences, mode):\n",
    "    global global_train_step, global_valid_step\n",
    "    test_predictions = {}\n",
    "    valid_predictions = {}\n",
    "    batch_generator = BatchGenerator(sequence=sequences, seq_len=SEQ_LEN, batch_size=BATCH_SIZE)\n",
    "    total_num_steps = int(1 + (batch_generator.indices[1] - 1) / SEQ_LEN)\n",
    "    controller_final_state_gt_cur, controller_final_state_autoregressive_cur = None, None\n",
    "    acc_loss = np.float128(0.0)\n",
    "    for step in range(total_num_steps):\n",
    "        feed_inputs, feed_targets = batch_generator.next()\n",
    "        feed_dict = {inputs : feed_inputs, targets : feed_targets}\n",
    "        if controller_final_state_autoregressive_cur is not None:\n",
    "            feed_dict.update({controller_initial_state_autoregressive : controller_final_state_autoregressive_cur})\n",
    "        if controller_final_state_gt_cur is not None:\n",
    "            feed_dict.update({controller_final_state_gt : controller_final_state_gt_cur})\n",
    "        if mode == \"train\":\n",
    "            feed_dict.update({keep_prob : KEEP_PROB_TRAIN})\n",
    "            summary, _, loss, controller_final_state_gt_cur, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([summaries, optimizer, mse_autoregressive_steering, controller_final_state_gt, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            train_writer.add_summary(summary, global_train_step)\n",
    "            global_train_step += 1\n",
    "        elif mode == \"valid\":\n",
    "            model_predictions, summary, loss, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, summaries, mse_autoregressive_steering, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)\n",
    "            valid_writer.add_summary(summary, global_valid_step)\n",
    "            global_valid_step += 1  \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            steering_targets = feed_targets[:, :, 0].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            stats = np.stack([steering_targets, model_predictions, (steering_targets - model_predictions)**2])\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                valid_predictions[img] = stats[:, i]\n",
    "        elif mode == \"test\":\n",
    "            model_predictions, controller_final_state_autoregressive_cur = \\\n",
    "                session.run([steering_predictions, controller_final_state_autoregressive],\n",
    "                           feed_dict = feed_dict)           \n",
    "            feed_inputs = feed_inputs[:, LEFT_CONTEXT:].flatten()\n",
    "            model_predictions = model_predictions.flatten()\n",
    "            for i, img in enumerate(feed_inputs):\n",
    "                test_predictions[img] = model_predictions[i]\n",
    "        if mode != \"test\":\n",
    "            acc_loss += loss\n",
    "            print('\\n' + str(step + 1) + \"/\" + str(total_num_steps) + \" - \" + str(np.sqrt(acc_loss / (step+1))))\n",
    "    return (np.sqrt(acc_loss / total_num_steps), valid_predictions) if mode != \"test\" else (None, test_predictions)\n",
    "NUM_EPOCHS=500\n",
    "best_validation_score = None\n",
    "with tf.compat.v1.Session(graph=graph, config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)) as session:\n",
    "    session.run(tf.compat.v1.initialize_all_variables())\n",
    "    print('Initialized')\n",
    "    ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if ckpt:\n",
    "        print(\"Restoring from\" + str(ckpt))\n",
    "        saver.restore(sess=session, save_path=ckpt)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print (\"Starting epoch %d\", epoch)\n",
    "        valid_score, valid_predictions = do_epoch(session=session, sequences=valid_seq, mode=\"valid\")\n",
    "        print (\"Validation Score: \" + str(valid_score))\n",
    "        if best_validation_score is None: \n",
    "            best_validation_score = valid_score\n",
    "        if valid_score < best_validation_score:\n",
    "            saver.save(session, 'v3/checkpoint-sdc-ch2')\n",
    "            best_validation_score = valid_score\n",
    "            print(\"\\n SAVED at epoch %d\", epoch)\n",
    "            with open(\"v3/valid-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                result = np.float128(0.0)\n",
    "                for img, stats in valid_predictions.items():\n",
    "                    #print >> out, img, stats\n",
    "                    print(out)\n",
    "                    print(img)\n",
    "                    print(stats)\n",
    "                    result += stats[-1]\n",
    "            print (\"Validation unnormalized RMSE:\" + str(np.sqrt(result / len(valid_predictions))))\n",
    "            with open(\"v3/test-predictions-epoch%d\" % epoch, \"w\") as out:\n",
    "                _, test_predictions = do_epoch(session=session, sequences=test_seq, mode=\"test\")\n",
    "                #print >> out,\n",
    "                print(out)\n",
    "                print(\"frame_id,steering_angle\")\n",
    "                for img, pred in test_predictions.items():\n",
    "                    img = img.replace(abs_path + \"test_center/\", \"\")\n",
    "                    #print >> out, \"%s,%f\" % (img, pred)\n",
    "                    print(out)\n",
    "                    print(img)\n",
    "                    print(pred)\n",
    "        if epoch != NUM_EPOCHS - 1:\n",
    "            print(\"Training\")\n",
    "            do_epoch(session=session, sequences=train_seq, mode=\"train\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "In addition to doing a restored_keras_model.summary(), you can save the model architecture as a png file using the plot_model API.\n",
    "from keras.utils import plot_model\n",
    "plot_model(restored_keras_model, to_file='model.png')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
